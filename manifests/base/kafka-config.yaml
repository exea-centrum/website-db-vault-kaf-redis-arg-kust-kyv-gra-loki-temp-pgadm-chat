apiVersion: v1
kind: ConfigMap
metadata:
  name: kafka-config
  namespace: davtrowebdbvault
  labels:
    app: website-db-vault-kaf-redis-arg-kust-kyv-gra-loki-temp-pgui
    app.kubernetes.io/name: website-db-vault-kaf-redis-arg-kust-kyv-gra-loki-temp-pgui
    app.kubernetes.io/instance: website-db-vault-kaf-redis-arg-kust-kyv-gra-loki-temp-pgui
data:
  server.properties: |
    # Kafka KRaft Mode Configuration
    process.roles=broker,controller
    node.id=0
    controller.quorum.voters=0@kafka-0.kafka.davtrowebdbvault.svc.cluster.local:9093

    # Listeners
    listeners=PLAINTEXT://:9092,CONTROLLER://:9093
    advertised.listeners=PLAINTEXT://kafka.davtrowebdbvault.svc.cluster.local:9092
    inter.broker.listener.name=PLAINTEXT
    listener.security.protocol.map=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
    controller.listener.names=CONTROLLER

    # Network Settings
    num.network.threads=3
    num.io.threads=8
    socket.send.buffer.bytes=102400
    socket.receive.buffer.bytes=102400
    socket.request.max.bytes=104857600

    # Log Settings
    log.dirs=/tmp/kafka-logs
    num.partitions=1
    num.recovery.threads.per.data.dir=1
        # User-provided Kafka KRaft server.properties
        process.roles=broker,controller
        node.id=0
        controller.quorum.voters=0@kafka-0.kafka.davtrowebdbvault.svc.cluster.local:9093

        # Listeners
        listeners=PLAINTEXT://:9092,CONTROLLER://:9093
        advertised.listeners=PLAINTEXT://kafka.davtrowebdbvault.svc.cluster.local:9092
        inter.broker.listener.name=PLAINTEXT
        listener.security.protocol.map=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
        controller.listener.names=CONTROLLER

        log.cleaner.dedupe.buffer.size=134217728
        log.cleaner.delete.retention.ms=86400000
        log.cleaner.enable=true
        log.cleaner.io.buffer.load.factor=0.9
        log.cleaner.io.buffer.size=524288
        log.cleaner.io.max.bytes.per.second=1.7976931348623157E308
        log.cleaner.max.compaction.lag.ms=9223372036854775807
        log.cleaner.min.cleanable.ratio=0.5
        log.cleaner.min.compaction.lag.ms=0
        log.cleaner.threads=1
        log.cleanup.policy=delete
        log.dir=/tmp/kafka-logs
        log.dir.failure.timeout.ms=30000
        log.dirs=/tmp/kafka-logs
        log.flush.interval.messages=9223372036854775807
        log.flush.interval.ms=
        log.flush.offset.checkpoint.interval.ms=60000
        log.flush.scheduler.interval.ms=9223372036854775807
        log.flush.start.offset.checkpoint.interval.ms=60000
        log.index.interval.bytes=4096
        log.index.size.max.bytes=10485760
        log.initial.task.delay.ms=30000
        log.local.retention.bytes=-2
        log.local.retention.ms=-2
        log.message.timestamp.after.max.ms=3600000
        log.message.timestamp.before.max.ms=9223372036854775807
        log.message.timestamp.type=CreateTime
        log.preallocate=false
        log.retention.bytes=-1
        log.retention.check.interval.ms=300000
        log.retention.hours=168
        log.segment.bytes=1073741824
        log.segment.delete.delay.ms=60000
        max.connection.creation.rate=2147483647
        max.connections=2147483647
        max.connections.per.ip=2147483647
        max.incremental.fetch.session.cache.slots=1000
        max.request.partition.size.limit=2000
        message.max.bytes=1048588
        metadata.log.max.record.bytes.between.snapshots=20971520
        metadata.log.max.snapshot.interval.ms=3600000
        metadata.log.segment.bytes=1073741824
        metadata.log.segment.ms=604800000
        metadata.max.idle.interval.ms=500
        metadata.max.retention.bytes=104857600
        metadata.max.retention.ms=604800000
        metric.reporters=org.apache.kafka.common.metrics.JmxReporter
        metrics.num.samples=2
        metrics.recording.level=INFO
        metrics.sample.window.ms=30000
        min.insync.replicas=1
        node.id=0
        num.io.threads=8
        num.network.threads=3
        num.partitions=1
        num.recovery.threads.per.data.dir=1
        num.replica.fetchers=1
        offset.metadata.max.bytes=4096
        offsets.commit.timeout.ms=5000
        offsets.load.buffer.size=5242880
        offsets.retention.check.interval.ms=600000
        offsets.retention.minutes=10080
        offsets.topic.num.partitions=50
        offsets.topic.replication.factor=1
        offsets.topic.segment.bytes=104857600
        process.roles=broker,controller
        producer.id.expiration.check.interval.ms=600000
        producer.id.expiration.ms=86400000
        producer.purgatory.purge.interval.requests=1000
        queued.max.request.bytes=-1
        queued.max.requests=500
        quota.window.num=11
        quota.window.size.seconds=1
        remote.fetch.max.wait.ms=500
        remote.list.offsets.request.timeout.ms=30000
        remote.log.index.file.cache.total.size.bytes=1073741824
        remote.log.manager.copier.thread.pool.size=10
        remote.log.manager.copy.max.bytes.per.second=9223372036854775807
        remote.log.manager.copy.quota.window.num=11
        remote.log.manager.copy.quota.window.size.seconds=1
        remote.log.manager.expiration.thread.pool.size=10
        remote.log.manager.fetch.max.bytes.per.second=9223372036854775807
        remote.log.manager.fetch.quota.window.num=11
        remote.log.manager.fetch.quota.window.size.seconds=1
        remote.log.manager.task.interval.ms=30000
        remote.log.manager.task.retry.backoff.max.ms=30000
        remote.log.manager.task.retry.backoff.ms=500
        remote.log.manager.task.retry.jitter=0.2
        remote.log.manager.thread.pool.size=2
        remote.log.metadata.custom.metadata.max.bytes=128
        remote.log.metadata.manager.class.name=org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
        remote.log.metadata.manager.impl.prefix=rlmm.config.
        remote.log.reader.max.pending.tasks=100
        remote.log.reader.threads=10
        remote.log.storage.manager.impl.prefix=rsm.config.
        remote.log.storage.system.enable=false
        replica.fetch.backoff.ms=1000
        replica.fetch.max.bytes=1048576
        replica.fetch.min.bytes=1
        replica.fetch.response.max.bytes=10485760
        replica.fetch.wait.max.ms=500
        replica.high.watermark.checkpoint.interval.ms=5000
        replica.lag.time.max.ms=30000
        replica.socket.receive.buffer.bytes=65536
        replica.socket.timeout.ms=30000
        replication.quota.window.num=11
        replication.quota.window.size.seconds=1
        request.timeout.ms=30000
        sasl.enabled.mechanisms=GSSAPI
        sasl.kerberos.kinit.cmd=/usr/bin/kinit
        sasl.kerberos.min.time.before.relogin=60000
        sasl.kerberos.principal.to.local.rules=DEFAULT
        sasl.kerberos.ticket.renew.jitter=0.05
        sasl.kerberos.ticket.renew.window.factor=0.8
        sasl.login.refresh.buffer.seconds=300
        sasl.login.refresh.min.period.seconds=60
        sasl.login.refresh.window.factor=0.8
        sasl.login.refresh.window.jitter=0.05
        sasl.login.retry.backoff.max.ms=10000
        sasl.login.retry.backoff.ms=100
        sasl.mechanism.controller.protocol=GSSAPI
        sasl.mechanism.inter.broker.protocol=GSSAPI
        sasl.oauthbearer.assertion.algorithm=RS256
        sasl.oauthbearer.jwks.endpoint.refresh.ms=3600000
        sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms=10000
        sasl.oauthbearer.jwks.endpoint.retry.backoff.ms=100
        sasl.oauthbearer.jwks.endpoint.url=
        sasl.oauthbearer.jwt.retriever.class=org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
        sasl.oauthbearer.jwt.validator.class=org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
        sasl.oauthbearer.clock.skew.seconds=30
        sasl.oauthbearer.scope.claim.name=scope
        sasl.oauthbearer.sub.claim.name=sub
        sasl.server.max.receive.size=524288
        security.inter.broker.protocol=PLAINTEXT
        server.max.startup.time.ms=9223372036854775807
        share.coordinator.append.linger.ms=5
        share.coordinator.cold.partition.snapshot.interval.ms=300000
        share.coordinator.load.buffer.size=5242880
        share.coordinator.snapshot.update.records.per.snapshot=500
        share.coordinator.state.topic.compression.codec=0
        share.coordinator.state.topic.min.isr=2
        share.coordinator.state.topic.num.partitions=50
        share.coordinator.state.topic.prune.interval.ms=300000
        share.coordinator.state.topic.replication.factor=3
        share.coordinator.state.topic.segment.bytes=104857600
        share.coordinator.threads=1
        share.coordinator.write.timeout.ms=5000
        share.fetch.purgatory.purge.interval.requests=1000
        socket.connection.setup.timeout.max.ms=30000
        socket.connection.setup.timeout.ms=10000
        socket.listen.backlog.size=50
        socket.receive.buffer.bytes=102400
        socket.request.max.bytes=104857600
        socket.send.buffer.bytes=102400
        ssl.allow.dn.changes=false
        ssl.allow.san.changes=false
        ssl.cipher.suites=[]
        ssl.client.auth=none
        ssl.enabled.protocols=TLSv1.2,TLSv1.3
        ssl.endpoint.identification.algorithm=https
        ssl.keymanager.algorithm=SunX509
        ssl.keystore.type=JKS
        ssl.principal.mapping.rules=DEFAULT
        ssl.protocol=TLSv1.3
        ssl.trustmanager.algorithm=PKIX
        telemetry.max.bytes=1048576
        transaction.abort.timed.out.transaction.cleanup.interval.ms=10000
        transaction.max.timeout.ms=900000
        transaction.partition.verification.enable=true
        transaction.remove.expired.transaction.cleanup.interval.ms=3600000
        transaction.state.log.load.buffer.size=5242880
        transaction.state.log.min.isr=1
        transaction.state.log.num.partitions=50
        transaction.state.log.replication.factor=1
        transaction.state.log.segment.bytes=104857600
        transaction.two.phase.commit.enable=false
        transactional.id.expiration.ms=604800000
        unclean.leader.election.enable=false
        unclean.leader.election.interval.ms=300000
        unstable.api.versions.enable=false
        unstable.feature.versions.enable=false